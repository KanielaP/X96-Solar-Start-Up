# Simple Agent

<img src="images/Basic Agent_Environment.png" align="middle" width="60%"/>

This is the basic environment that will be the baseline to train the agent. 

## Description

This environment randomly generates solar charge, temperature and load consumption that is sent to the agent to process. The initial battery level is 0kw, but on reoccuring runs it will take the projected battery level value. This process is expected every hour after the agent's action. 

## Action Space

The action is a (enter human interaction components and what it uses to store values) 

## Observation Space

-  Load(kw/h): House Consumption of Electricity
-  Solar(kw/h): Electricity Generated by Solar Panels
-  Capacity(kw): Max Capacty of Battery
-  Battery(kw): Current Battery Charge
-  Temperature(Â°C): Current Temperature of Weather

| Parameters | Values         | 
|------------|----------------|
| Load       | RNG |
| Solar      | RNG | 
| Capacity   | RNG | 
| Battery    | Battery Projection | 
| Temperature| RNG | 

NOTE: This is based off of code, update when code line is available
<br> All random value observations are uniform.  
<br> Battery Projection = Previous run instance (Battery + Solar - Load), otherwise 0.   

## Starting State

| Parameters | Values         | 
|------------|----------------|
| Load       | 0              |
| Solar      | 0              | 
| Capacity   | 0              | 
| Battery    | 0              | 
| Temperature| 0              | 

## Environment End

Human input to rerun the code to generate new values to train the agent. There are also special cases where it will restart.  

-  If Battery > Capacity 

## Arguements 


